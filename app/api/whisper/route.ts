/**
 * ğŸ¤ Whisper Transcription API
 * èªéŸ³è½‰æ–‡å­—æœå‹™
 * 
 * åŠŸèƒ½ï¼š
 * 1. æ¥æ”¶éŸ³è¨Šæª”æ¡ˆ
 * 2. å‘¼å« OpenAI Whisper API
 * 3. å›å‚³è½‰éŒ„æ–‡å­—
 */

import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';

const openai = new OpenAI({
    apiKey: process.env.CHATKIT_API_KEY || process.env.OPENAI_API_KEY || '',
});

export async function POST(req: NextRequest) {
    try {
        const formData = await req.formData();
        const audioFile = formData.get('audio') as File;

        if (!audioFile) {
            return NextResponse.json(
                { error: 'Missing audio file' },
                { status: 400 }
            );
        }

        // å‘¼å« Whisper API
        const transcription = await openai.audio.transcriptions.create({
            file: audioFile,
            model: 'whisper-1',
            language: 'zh', // ä¸­æ–‡
        });

        return NextResponse.json({
            text: transcription.text,
            language: 'zh',
        });
    } catch (error) {
        console.error('Whisper API error:', error);
        return NextResponse.json(
            { error: 'Failed to transcribe audio' },
            { status: 500 }
        );
    }
}
